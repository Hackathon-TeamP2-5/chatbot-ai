# Chatbot AI

## Introduction
In this repository we have done all of the data analysis and fine-tunining work and we have provided all of the deployed models and datasets resources.

## Outline:
1. We installed dependencies and load the dataset from hugging face, and then fine tuned llama 3.2 1B model in `Spark2.ipynb` notebook.
2. We deployed the model on hugging face and also on ollama.

## Future work:
1. We have create a new dataset contains the English conversations in the first dataset and also with Arabic conversations and then we shuffled them using Pandas as we did in `data_preparation.ipynb` notebook.
2. Soon we will train the model on the new dataset to allow users to send Arabic and English messages to our model.


## Resources:
1. Ar-En version dataset on hugging face: [Dataset](https://huggingface.co/datasets/baraalsedih/mental_health_counseling_conversations_en_ar)
2. Fine-Tuned model on hugging face: [Model](https://huggingface.co/baraalsedih/llama3.2_Spark_TeamP2_5)
3. Ollama deployed model: [Ollama](https://ollama.com/baraalsedih/llama_spark_teamp2-5)

## Contacts:
For more informations about how we fine-tuned our model I can provide you a step by step tutorial to do that, just contact me here or on my email address `baraalsedih@gmail.com`.
